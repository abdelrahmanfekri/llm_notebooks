{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated, List\n",
    "import operator\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage, ChatMessage\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLAN_PROMPT = \"\"\"You are an expert writer tasked with writing a high level outline of an essay. \\\n",
    "Write such an outline for the user provided topic. Give an outline of the essay along with any relevant notes \\\n",
    "or instructions for the sections.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITER_PROMPT = \"\"\"You are an essay assistant tasked with writing excellent 5-paragraph essays.\\\n",
    "Generate the best essay possible for the user's request and the initial outline. \\\n",
    "If the user provides critique, respond with a revised version of your previous attempts. \\\n",
    "Utilize all the information below as needed: \n",
    "\n",
    "------\n",
    "\n",
    "{content}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "REFLECTION_PROMPT = \"\"\"You are a teacher grading an essay submission. \\\n",
    "Generate critique and recommendations for the user's submission. \\\n",
    "Provide detailed recommendations, including requests for length, depth, style, etc.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCH_PLAN_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when writing the following essay. Generate a list of search queries that will gather \\\n",
    "any relevant information. Only generate 3 queries max.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCH_CRITIQUE_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when making any requested revisions (as outlined below). \\\n",
    "Generate a list of search queries that will gather any relevant information. Only generate 3 queries max.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "class Queries(BaseModel):\n",
    "    queries: List[str]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "import os\n",
    "tavily = TavilyClient(api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    task: str\n",
    "    plan: str\n",
    "    draft: str\n",
    "    critique: str\n",
    "    content: List[str]\n",
    "    revision_number: int\n",
    "    max_revisions: int\n",
    "    \n",
    "def plan_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=PLAN_PROMPT), \n",
    "        HumanMessage(content=state['task'])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"plan\": response.content}\n",
    "\n",
    "def research_plan_node(state: AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_PLAN_PROMPT),\n",
    "        HumanMessage(content=state['task'])\n",
    "    ])\n",
    "    content = state['content'] or []\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response['results']:\n",
    "            content.append(r['content'])\n",
    "    return {\"content\": content}\n",
    "\n",
    "def generation_node(state: AgentState):\n",
    "    content = \"\\n\\n\".join(state['content'] or [])\n",
    "    user_message = HumanMessage(\n",
    "        content=f\"{state['task']}\\n\\nHere is my plan:\\n\\n{state['plan']}\")\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=WRITER_PROMPT.format(content=content)\n",
    "        ),\n",
    "        user_message\n",
    "        ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\n",
    "        \"draft\": response.content, \n",
    "        \"revision_number\": state.get(\"revision_number\", 0) + 1\n",
    "    }\n",
    "\n",
    "def reflection_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=REFLECTION_PROMPT), \n",
    "        HumanMessage(content=state['draft'])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"critique\": response.content}\n",
    "\n",
    "\n",
    "def research_critique_node(state: AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_CRITIQUE_PROMPT),\n",
    "        HumanMessage(content=state['critique'])\n",
    "    ])\n",
    "    content = state['content'] or []\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response['results']:\n",
    "            content.append(r['content'])\n",
    "    return {\"content\": content}\n",
    "\n",
    "def should_continue(state):\n",
    "    if state[\"revision_number\"] > state[\"max_revisions\"]:\n",
    "        return END\n",
    "    return \"reflect\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(AgentState)\n",
    "builder.add_node(\"planner\", plan_node)\n",
    "builder.add_node(\"generate\", generation_node)\n",
    "builder.add_node(\"reflect\", reflection_node)\n",
    "builder.add_node(\"research_plan\", research_plan_node)\n",
    "builder.add_node(\"research_critique\", research_critique_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.set_entry_point(\"planner\")\n",
    "builder.add_conditional_edges(\n",
    "    \"generate\", \n",
    "    should_continue, \n",
    "    {END: END, \"reflect\": \"reflect\"}\n",
    ")\n",
    "builder.add_edge(\"planner\", \"research_plan\")\n",
    "builder.add_edge(\"research_plan\", \"generate\")\n",
    "\n",
    "builder.add_edge(\"reflect\", \"research_critique\")\n",
    "builder.add_edge(\"research_critique\", \"generate\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'planner': {'plan': 'I. Introduction\\n    A. Brief overview of Langchain and Langsmith\\n    B. Thesis statement: Exploring the differences between Langchain and Langsmith\\n\\nII. Langchain\\n    A. Definition and purpose\\n    B. Key features and characteristics\\n    C. Use cases and applications\\n    D. Advantages and limitations\\n\\nIII. Langsmith\\n    A. Definition and purpose\\n    B. Key features and characteristics\\n    C. Use cases and applications\\n    D. Advantages and limitations\\n\\nIV. Comparison between Langchain and Langsmith\\n    A. Technology stack and architecture\\n    B. Scalability and performance\\n    C. Security and privacy considerations\\n    D. Adoption and industry trends\\n\\nV. Conclusion\\n    A. Recap of key differences between Langchain and Langsmith\\n    B. Implications for future developments in the field\\n    C. Final thoughts on the significance of understanding these technologies.'}}\n",
      "{'research_plan': {'content': ['Langchain vs Langsmith: Unpacking the AI Language Model Showdown\\nOverview of Langchain and Langsmith\\nLangchain is a versatile open-source framework that enables you to build applications utilizing large language models (LLM) like GPT-3. Check out our free WhatsApp channel to stay educated on LLM developments:\\nJoin the Finxter Academy and unlock access to premium courses ðŸ‘‘ to certify your skills in exponential technologies and programming.\\n Frequently Asked Questions\\nWhether youâ€™re trying to figure out which tool fits your needs or youâ€™re just getting started with language model automation, these FAQs will help shed light on the common curiosities about Langchain and LangSmith.\\n The best way to find out is to reach out to them through the LangSmith Walkthrough page or to inquire about access directly through their support channels.\\n Hereâ€™s how you might start a simple Langchain project in Python:\\nTo integrate LangSmith, you could write something like this:\\nYouâ€™re not limited to Python, though.', \"LangSmith Cookbook: Real-world Lang Smith Examples\\nThe LangSmith Cookbook is not just a compilation of code snippets; it's a goldmine of hands-on examples designed to inspire and assist you in your projects. On This Page\\nLangSmith: Best Way to Test LLMs and AI Application\\nPublished on 12/17/2023\\nIf you're in the world of Language Learning Models (LLMs), you've probably heard of LangSmith. How to Download Feedback and Examples (opens in a new tab): Export predictions, evaluation results, and other information to add to your reports programmatically.\\n This article is your one-stop guide to understanding LangSmith, a platform that offers a plethora of features for debugging, testing, evaluating, and monitoring LLM applications.\\n How do I get access to LangSmith?\\nTo get access to LangSmith, you'll need to sign up for an account on their website.\", 'Langchain vs Langsmith: Unpacking the AI Language Model Showdown\\nOverview of Langchain and Langsmith\\nLangchain is a versatile open-source framework that enables you to build applications utilizing large language models (LLM) like GPT-3. Check out our free WhatsApp channel to stay educated on LLM developments:\\nJoin the Finxter Academy and unlock access to premium courses ðŸ‘‘ to certify your skills in exponential technologies and programming.\\n Frequently Asked Questions\\nWhether youâ€™re trying to figure out which tool fits your needs or youâ€™re just getting started with language model automation, these FAQs will help shed light on the common curiosities about Langchain and LangSmith.\\n The best way to find out is to reach out to them through the LangSmith Walkthrough page or to inquire about access directly through their support channels.\\n Hereâ€™s how you might start a simple Langchain project in Python:\\nTo integrate LangSmith, you could write something like this:\\nYouâ€™re not limited to Python, though.', \"This was such an important unlock for us as we build in tactical functionality to our AI.\\nAdvice for Product Teams Considering LangSmith\\nWhen you're in the thick of product development, the whirlwind of AI and LLMs can be overwhelming. ou can now clearly see the citations coming through with the responses in the traces, and weâ€™re good to ship the changes to the prompt to prod.\\n We do this primarily to legitimize the LLMs response and give our HelpHub customerâ€™s peace of mind that their end users are in fact getting to the help resource they need (instead of an LLM just hallucinating and giving any response it wants.)\\n Take it from us, as we integrated AI more heavily and widely across our products, weâ€™ve been more conscious than ever that the quality of the outputs matches the quality and trust that our customers have in our product. We updated our prompt to be more firm when asking for the sources:\\nWe then tested everything using LangSmith evals, to make sure that it fixes the issue before pushing to production.\\n\", 'LangSmith supports a powerful comparison view that lets you hone in on key differences, regressions, and improvements between different experiments. Open the comparison view To open the comparison view, select two or more experiments from the \"Experiments\" tab from a given dataset page. Then, click on the \"Compare\" button at the bottom of the page.', 'Langchain vs Langsmith: Unpacking the AI Language Model Showdown\\nOverview of Langchain and Langsmith\\nLangchain is a versatile open-source framework that enables you to build applications utilizing large language models (LLM) like GPT-3. Check out our free WhatsApp channel to stay educated on LLM developments:\\nJoin the Finxter Academy and unlock access to premium courses ðŸ‘‘ to certify your skills in exponential technologies and programming.\\n Frequently Asked Questions\\nWhether youâ€™re trying to figure out which tool fits your needs or youâ€™re just getting started with language model automation, these FAQs will help shed light on the common curiosities about Langchain and LangSmith.\\n The best way to find out is to reach out to them through the LangSmith Walkthrough page or to inquire about access directly through their support channels.\\n Hereâ€™s how you might start a simple Langchain project in Python:\\nTo integrate LangSmith, you could write something like this:\\nYouâ€™re not limited to Python, though.']}}\n",
      "{'generate': {'draft': \"**Title: Langchain vs Langsmith: Contrasting Two AI Language Models**\\n\\nI. **Introduction**\\n   \\n   In the realm of AI language models, Langchain and Langsmith stand out as prominent frameworks. While both serve the purpose of enabling applications with large language models, they possess unique characteristics that set them apart. This essay delves into the disparities between Langchain and Langsmith to provide a comprehensive understanding of their functionalities.\\n\\nII. **Langchain**\\n\\n   A. **Definition and Purpose**\\n   \\n   Langchain is an open-source framework designed to facilitate the development of applications utilizing large language models like GPT-3.\\n   \\n   B. **Key Features and Characteristics**\\n   \\n   It offers versatility and flexibility in building AI-powered solutions, making it accessible for various projects.\\n   \\n   C. **Use Cases and Applications**\\n   \\n   Langchain finds applications in chatbots, content generation, and automated text analysis, among others.\\n   \\n   D. **Advantages and Limitations**\\n   \\n   Advantages include its open-source nature and broad language model support, while limitations may involve scalability challenges for extremely large models.\\n\\nIII. **Langsmith**\\n\\n   A. **Definition and Purpose**\\n   \\n   Langsmith is a platform known for its debugging, testing, evaluating, and monitoring features for language learning models.\\n   \\n   B. **Key Features and Characteristics**\\n   \\n   It provides tools for exporting predictions, evaluation results, and other data crucial for enhancing AI applications.\\n   \\n   C. **Use Cases and Applications**\\n   \\n   Langsmith is essential for developers working with language models to ensure the accuracy and efficiency of their applications.\\n   \\n   D. **Advantages and Limitations**\\n   \\n   Its advantages lie in its comprehensive testing capabilities, while limitations may include a steeper learning curve for beginners.\\n\\nIV. **Comparison between Langchain and Langsmith**\\n\\n   A. **Technology Stack and Architecture**\\n   \\n   Langchain focuses on building applications with language models, while Langsmith emphasizes testing and evaluation tools.\\n   \\n   B. **Scalability and Performance**\\n   \\n   Langchain may excel in scalability due to its framework nature, whereas Langsmith prioritizes performance testing for accuracy.\\n   \\n   C. **Security and Privacy Considerations**\\n   \\n   Both frameworks likely have robust security measures, but Langsmith's testing tools may enhance privacy compliance.\\n   \\n   D. **Adoption and Industry Trends**\\n   \\n   Langchain may be more widely adopted for application development, while Langsmith's tools are crucial for ensuring the quality of AI applications.\\n\\nV. **Conclusion**\\n\\n   A. **Recap of Key Differences**\\n   \\n   Langchain and Langsmith differ in their primary focuses, with Langchain catering to application development and Langsmith specializing in testing and evaluation.\\n   \\n   B. **Implications for Future Developments**\\n   \\n   Understanding the distinctions between these frameworks is vital for leveraging their strengths effectively in AI projects.\\n   \\n   C. **Final Thoughts**\\n   \\n   As the AI landscape continues to evolve, grasping the nuances of tools like Langchain and Langsmith is essential for driving innovation and efficiency in language model applications.\", 'revision_number': 2}}\n",
      "{'reflect': {'critique': '**Overall Feedback:**\\nThe essay provides a structured comparison between Langchain and Langsmith, highlighting their definitions, key features, use cases, advantages, limitations, and comparisons. The content is informative and well-organized, making it easy for readers to understand the differences between the two frameworks. However, there are areas where the essay can be improved to enhance its depth and clarity.\\n\\n**Content and Depth:**\\n1. **Expand on Use Cases and Applications:** While the essay briefly mentions some applications of Langchain and Langsmith, it would be beneficial to provide more detailed examples or case studies to illustrate how these frameworks are utilized in real-world scenarios. This would help readers better understand the practical implications of using Langchain and Langsmith.\\n\\n2. **Include Real-World Examples:** Incorporating specific examples of companies or projects that have successfully implemented Langchain and Langsmith would add credibility to the essay. It would also demonstrate the effectiveness of these frameworks in different contexts.\\n\\n3. **Discuss User Experience:** Consider including a section that delves into the user experience of working with Langchain and Langsmith. This could involve discussing ease of use, documentation quality, community support, and any unique features that enhance the overall user experience.\\n\\n**Style and Clarity:**\\n1. **Enhance Transition Between Sections:** To improve the flow of the essay, ensure smooth transitions between sections. Each section should logically lead to the next, creating a cohesive narrative that guides the reader through the comparison of Langchain and Langsmith.\\n\\n2. **Clarify Technical Terminology:** While the essay provides a good overview of the frameworks, consider explaining technical terms or concepts in simpler language for readers who may not be familiar with AI or programming. This will make the content more accessible to a broader audience.\\n\\n**Recommendations:**\\n1. **Case Studies and Examples:** Incorporate case studies or examples to illustrate the practical applications of Langchain and Langsmith in different industries or projects.\\n\\n2. **User Experience Analysis:** Include a section that evaluates the user experience of working with Langchain and Langsmith, highlighting usability, support, and overall satisfaction.\\n\\n3. **Expanded Use Cases:** Provide more detailed use cases for both frameworks to showcase their versatility and applicability across various domains.\\n\\n4. **In-depth Comparison:** Consider expanding the comparison section to include a deeper analysis of how Langchain and Langsmith stack up against each other in terms of specific features, performance metrics, and industry adoption.\\n\\n5. **Conclusion Reflection:** In the conclusion, reflect on the potential future developments in AI language models and how Langchain and Langsmith could evolve to meet emerging challenges or trends in the field.\\n\\nBy incorporating these recommendations, you can enrich the essay with more detailed insights, practical examples, and a deeper analysis of the two frameworks, making it a more comprehensive and engaging read for your audience.'}}\n",
      "{'research_critique': {'content': ['Langchain vs Langsmith: Unpacking the AI Language Model Showdown\\nOverview of Langchain and Langsmith\\nLangchain is a versatile open-source framework that enables you to build applications utilizing large language models (LLM) like GPT-3. Check out our free WhatsApp channel to stay educated on LLM developments:\\nJoin the Finxter Academy and unlock access to premium courses ðŸ‘‘ to certify your skills in exponential technologies and programming.\\n Frequently Asked Questions\\nWhether youâ€™re trying to figure out which tool fits your needs or youâ€™re just getting started with language model automation, these FAQs will help shed light on the common curiosities about Langchain and LangSmith.\\n The best way to find out is to reach out to them through the LangSmith Walkthrough page or to inquire about access directly through their support channels.\\n Hereâ€™s how you might start a simple Langchain project in Python:\\nTo integrate LangSmith, you could write something like this:\\nYouâ€™re not limited to Python, though.', \"LangSmith Cookbook: Real-world Lang Smith Examples\\nThe LangSmith Cookbook is not just a compilation of code snippets; it's a goldmine of hands-on examples designed to inspire and assist you in your projects. On This Page\\nLangSmith: Best Way to Test LLMs and AI Application\\nPublished on 12/17/2023\\nIf you're in the world of Language Learning Models (LLMs), you've probably heard of LangSmith. How to Download Feedback and Examples (opens in a new tab): Export predictions, evaluation results, and other information to add to your reports programmatically.\\n This article is your one-stop guide to understanding LangSmith, a platform that offers a plethora of features for debugging, testing, evaluating, and monitoring LLM applications.\\n How do I get access to LangSmith?\\nTo get access to LangSmith, you'll need to sign up for an account on their website.\", 'Langchain vs Langsmith: Unpacking the AI Language Model Showdown\\nOverview of Langchain and Langsmith\\nLangchain is a versatile open-source framework that enables you to build applications utilizing large language models (LLM) like GPT-3. Check out our free WhatsApp channel to stay educated on LLM developments:\\nJoin the Finxter Academy and unlock access to premium courses ðŸ‘‘ to certify your skills in exponential technologies and programming.\\n Frequently Asked Questions\\nWhether youâ€™re trying to figure out which tool fits your needs or youâ€™re just getting started with language model automation, these FAQs will help shed light on the common curiosities about Langchain and LangSmith.\\n The best way to find out is to reach out to them through the LangSmith Walkthrough page or to inquire about access directly through their support channels.\\n Hereâ€™s how you might start a simple Langchain project in Python:\\nTo integrate LangSmith, you could write something like this:\\nYouâ€™re not limited to Python, though.', \"This was such an important unlock for us as we build in tactical functionality to our AI.\\nAdvice for Product Teams Considering LangSmith\\nWhen you're in the thick of product development, the whirlwind of AI and LLMs can be overwhelming. ou can now clearly see the citations coming through with the responses in the traces, and weâ€™re good to ship the changes to the prompt to prod.\\n We do this primarily to legitimize the LLMs response and give our HelpHub customerâ€™s peace of mind that their end users are in fact getting to the help resource they need (instead of an LLM just hallucinating and giving any response it wants.)\\n Take it from us, as we integrated AI more heavily and widely across our products, weâ€™ve been more conscious than ever that the quality of the outputs matches the quality and trust that our customers have in our product. We updated our prompt to be more firm when asking for the sources:\\nWe then tested everything using LangSmith evals, to make sure that it fixes the issue before pushing to production.\\n\", 'LangSmith supports a powerful comparison view that lets you hone in on key differences, regressions, and improvements between different experiments. Open the comparison view To open the comparison view, select two or more experiments from the \"Experiments\" tab from a given dataset page. Then, click on the \"Compare\" button at the bottom of the page.', 'Langchain vs Langsmith: Unpacking the AI Language Model Showdown\\nOverview of Langchain and Langsmith\\nLangchain is a versatile open-source framework that enables you to build applications utilizing large language models (LLM) like GPT-3. Check out our free WhatsApp channel to stay educated on LLM developments:\\nJoin the Finxter Academy and unlock access to premium courses ðŸ‘‘ to certify your skills in exponential technologies and programming.\\n Frequently Asked Questions\\nWhether youâ€™re trying to figure out which tool fits your needs or youâ€™re just getting started with language model automation, these FAQs will help shed light on the common curiosities about Langchain and LangSmith.\\n The best way to find out is to reach out to them through the LangSmith Walkthrough page or to inquire about access directly through their support channels.\\n Hereâ€™s how you might start a simple Langchain project in Python:\\nTo integrate LangSmith, you could write something like this:\\nYouâ€™re not limited to Python, though.', \"LangSmith Cookbook: Real-world Lang Smith Examples\\nThe LangSmith Cookbook is not just a compilation of code snippets; it's a goldmine of hands-on examples designed to inspire and assist you in your projects. On This Page\\nLangSmith: Best Way to Test LLMs and AI Application\\nPublished on 12/17/2023\\nIf you're in the world of Language Learning Models (LLMs), you've probably heard of LangSmith. How to Download Feedback and Examples (opens in a new tab): Export predictions, evaluation results, and other information to add to your reports programmatically.\\n This article is your one-stop guide to understanding LangSmith, a platform that offers a plethora of features for debugging, testing, evaluating, and monitoring LLM applications.\\n How do I get access to LangSmith?\\nTo get access to LangSmith, you'll need to sign up for an account on their website.\", 'Sign up\\nSign in\\nSign up\\nSign in\\nMember-only story\\nEnhancing Language Model Applications with LangChain: Practical Use Cases and Code Examples\\nThe Data Beast\\nFollow\\n--\\nShare\\nIntroduction to LangChain\\nLangChain is a framework designed to amplify the capabilities of language models. This framework is comprised of LangChain Libraries, LangChain Templates, LangServe, and LangSmith, offering a comprehensive suite of tools for developers working with language models\\u200b\\u200b.\\nCore Components of LangChain\\nLangChain Libraries\\nThese libraries provide modular, easy-to-use tools and integrations, simplifying the construction of complex chains for various tasks\\u200b\\u200b.\\nLangChain Expression Language (LCEL)\\nLCEL is a declarative language within LangChain, allowing for the seamless composition of chains from simple to complex tasks\\u200b\\u200b.\\nLangChain in Action: Real-World Examples\\n1. --\\n--\\nWritten by The Data Beast\\nHelp\\nStatus\\nAbout\\nCareers\\nBlog\\nPrivacy\\nTerms\\nText to speech\\nTeams Document Question Answering\\nLangChain can efficiently interface with a document database to extract and synthesize information in response to queries.\\n Analyzing Structured Data\\nLangChain is also adept at processing and extracting insights from structured data, such as financial reports or customer databases.\\n', \"Rakuten Group builds with LangChain and LangSmith to deliver premium products for its business clients\\nLangChain Partners with CommandBar on their Copilot User Assistant\\nLangChain partners with Elastic to launch the Elastic AI Assistant\\nAlly Financial Collaborates with LangChain to Deliver Coding Module to Mask PII\\nLLMs accelerate Adyen's support team through\\nsmart-ticket routing and support agent copilot\\nMorningstar Intelligence Engine puts personalized investment insights at analysts' fingertips\\nRobocorpâ€™s code generation assistant makes building Python automation easy for developers\\nLangChain Expands Collaboration with Microsoft\\nHear from our happy customers\\nLangSmith helps teams of all sizes, across all industries, from ambitious\\nstartups to established enterprises.\\n We could have built evaluation, testing and monitoring tools in house, but with LangSmith it took us 10x less time to get a 1000x better tool.â€\\nReady to start shipping\\nreliable GenAI apps faster?\\nLangChain and LangSmith are critical parts of the reference\\narchitecture to get you from prototype to production. We couldnâ€™t have achieved \\xa0the product experience delivered to our customers without LangChain, and we couldnâ€™t have done it at the same pace without LangSmith.â€\\nâ€œAs soon as we heard about LangSmith, we moved our entire development stack onto it. We couldnâ€™t have achieved \\xa0the product experience delivered to our customers without LangChain, and we couldnâ€™t have done it at the same pace without LangSmith.â€\\nâ€œAs soon as we heard about LangSmith, we moved our entire development stack onto it. We could have built evaluation, testing and monitoring tools in house, but with LangSmith it took us 10x less time to get a 1000x better tool.â€\\nâ€œLangSmith helped us improve the accuracy and performance of Retoolâ€™s fine-tuned models.\", 'In 2023, LangChain seemed ideal. It offered impressive components and tools and was gaining popularity. LangChain promised \"to turn an idea into working code in an afternoon,\" but as our needs grew complex, problems emerged. LangChain became a hindrance rather than a productivity booster.', \"LangSmith makes it easy to attach user feedback to traces. It's often helpful to expose a simple mechanism (such as a thumbs-up, thumbs-down button) to collect user feedback for your application responses. You can then use the LangSmith SDK or API to send feedback for a trace. To get the run_id of a logged run, see this guide.\", \"This was such an important unlock for us as we build in tactical functionality to our AI.\\nAdvice for Product Teams Considering LangSmith\\nWhen you're in the thick of product development, the whirlwind of AI and LLMs can be overwhelming. ou can now clearly see the citations coming through with the responses in the traces, and weâ€™re good to ship the changes to the prompt to prod.\\n We do this primarily to legitimize the LLMs response and give our HelpHub customerâ€™s peace of mind that their end users are in fact getting to the help resource they need (instead of an LLM just hallucinating and giving any response it wants.)\\n Take it from us, as we integrated AI more heavily and widely across our products, weâ€™ve been more conscious than ever that the quality of the outputs matches the quality and trust that our customers have in our product. We updated our prompt to be more firm when asking for the sources:\\nWe then tested everything using LangSmith evals, to make sure that it fixes the issue before pushing to production.\\n\"]}}\n",
      "{'generate': {'draft': \"**Title: Langchain vs Langsmith: Contrasting Two AI Language Models**\\n\\nI. Introduction\\nIn the realm of AI language models, Langchain and Langsmith stand out as prominent frameworks. Langchain is known for its versatility in building applications using large language models like GPT-3, while Langsmith offers a platform with a plethora of features for debugging, testing, evaluating, and monitoring LLM applications. This essay aims to delve into the disparities between Langchain and Langsmith.\\n\\nII. Langchain\\nLangchain is a comprehensive open-source framework designed to facilitate the development of applications leveraging large language models. It offers modular tools and integrations, such as the LangChain Expression Language (LCEL), making it easier to construct complex chains for various tasks. Langchain excels in tasks like interfacing with document databases for information extraction and analyzing structured data from financial reports or customer databases.\\n\\nIII. Langsmith\\nOn the other hand, Langsmith is a platform that focuses on testing, debugging, and evaluating LLM applications. It provides a comparison view to identify key differences, regressions, and improvements between different experiments. Langsmith also allows for user feedback to be attached to traces, ensuring the legitimacy and quality of AI responses before deployment.\\n\\nIV. Comparison between Langchain and Langsmith\\nA. **Technology Stack and Architecture:** Langchain emphasizes building applications with large language models, while Langsmith focuses on testing and debugging these applications.\\nB. **Scalability and Performance:** Langchain offers a versatile framework for application development, whereas Langsmith enhances the quality and accuracy of AI responses through testing and evaluation.\\nC. **Security and Privacy Considerations:** Both Langchain and Langsmith prioritize data security and privacy, but Langsmith's focus on testing can help ensure the reliability of AI applications.\\nD. **Adoption and Industry Trends:** Langchain is popular for its development capabilities, while Langsmith is gaining traction for its testing and evaluation features.\\n\\nV. Conclusion\\nIn conclusion, understanding the distinctions between Langchain and Langsmith is crucial for developers and organizations working with AI language models. While Langchain excels in application development, Langsmith plays a vital role in ensuring the quality and reliability of AI applications. By recognizing the strengths and limitations of each framework, stakeholders can make informed decisions for their projects, ultimately advancing the field of AI language models.\", 'revision_number': 3}}\n"
     ]
    }
   ],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for s in graph.stream({\n",
    "    'task': \"what is the difference between langchain and langsmith\",\n",
    "    \"max_revisions\": 2,\n",
    "    \"revision_number\": 1,\n",
    "}, thread):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CompiledStateGraph' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CompiledStateGraph' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
